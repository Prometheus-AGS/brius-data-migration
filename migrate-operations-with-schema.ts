import { createClient } from '@supabase/supabase-js';
import * as dotenv from 'dotenv';
import { Client } from 'pg';

dotenv.config();

const supabase = createClient(process.env.SUPABASE_URL!, process.env.SUPABASE_SERVICE_ROLE!);

async function insertInBatches(tableName: string, data: any[]): Promise<number> {
  const batchSize = 50;
  let totalInserted = 0;

  for (let i = 0; i < data.length; i += batchSize) {
    const batch = data.slice(i, i + batchSize);

    try {
      const { error } = await supabase
        .from(tableName)
        .insert(batch);

      if (error) {
        console.error(`   âŒ Error inserting batch for ${tableName}:`, error.message);
        if (batch.length > 0) {
          console.error(`   First item structure:`, JSON.stringify(batch[0], null, 2));
        }
        continue;
      }

      totalInserted += batch.length;
      console.log(`   âœ… Inserted ${batch.length} records for ${tableName} (total: ${totalInserted})`);

    } catch (batchError: any) {
      console.error(`   âŒ Batch error for ${tableName}:`, batchError.message);
    }
  }

  return totalInserted;
}

async function migrateOperationsWithSchema() {
  console.log('ðŸš€ Starting operations migration with updated schema (metadata, created_at, updated_at)...\n');

  const sourceClient = new Client({
    host: process.env.SOURCE_DB_HOST!,
    port: parseInt(process.env.SOURCE_DB_PORT!),
    user: process.env.SOURCE_DB_USER!,
    password: process.env.SOURCE_DB_PASSWORD!,
    database: process.env.SOURCE_DB_NAME!,
  });

  try {
    await sourceClient.connect();
    console.log('âœ… Connected to source database');

    // Get a default case to use for operations
    console.log('\nðŸ“‹ Getting default case for operations...');
    const { data: defaultCase } = await supabase
      .from('cases')
      .select('id')
      .limit(1)
      .single();

    if (!defaultCase) {
      console.log('âŒ No cases found - cannot migrate operations without case_id');
      return 0;
    }

    console.log(`âœ… Using default case: ${defaultCase.id}`);

    // Get source operations data
    console.log('\nâš™ï¸ Fetching operations from dispatch_operation...');
    const operationsResult = await sourceClient.query(`
      SELECT
        id,
        type,
        made_at,
        price,
        sq_order_id,
        sq_payment_id,
        sq_refund_id,
        card_brand,
        card_bin,
        card_last,
        office_card,
        payment_id,
        attempts
      FROM dispatch_operation
      ORDER BY id;
    `);

    console.log(`ðŸ“Š Found ${operationsResult.rows.length} operations to migrate`);

    // Get type distribution
    const typeStats = operationsResult.rows.reduce((acc: any, row: any) => {
      acc[row.type || 'NULL'] = (acc[row.type || 'NULL'] || 0) + 1;
      return acc;
    }, {});
    console.log(`ðŸ“ˆ Operation types in source:`, typeStats);

    const totalValue = operationsResult.rows.reduce((sum: number, row: any) => sum + parseFloat(row.price || '0'), 0);
    console.log(`ðŸ’° Total value: $${totalValue.toFixed(2)}`);

    // Map source data to target schema with all available fields
    const operations = operationsResult.rows.map((row: any) => {
      // Map type numbers to operation types (handle null/undefined safely)
      let operationType = 'payment'; // Default
      if (row.type === 1) operationType = 'payment';
      else if (row.type === 2) operationType = 'refund';
      else if (row.type === null || row.type === undefined) operationType = 'payment';

      return {
        case_id: defaultCase.id, // Required
        operation_type: operationType, // Required
        created_at: row.made_at || new Date().toISOString(),
        updated_at: row.made_at || new Date().toISOString(),
        metadata: {
          legacy_id: row.id,
          source_type: row.type,
          sq_order_id: row.sq_order_id,
          sq_payment_id: row.sq_payment_id,
          sq_refund_id: row.sq_refund_id,
          card_brand: row.card_brand,
          card_bin: row.card_bin,
          card_last: row.card_last,
          office_card: row.office_card,
          payment_id: row.payment_id,
          attempts: row.attempts,
          price: parseFloat(row.price || '0'),
          migration_timestamp: new Date().toISOString()
        }
      };
    });

    console.log(`\nðŸ“¦ Prepared ${operations.length} operations for insertion`);

    // Show sample operation
    if (operations.length > 0) {
      console.log('\nðŸ“‹ Sample operation:');
      console.log(JSON.stringify(operations[0], null, 2));
    }

    console.log(`ðŸ’° Total value to migrate: $${operations.reduce((sum: number, op: any) => {
      return sum + (parseFloat(op.metadata?.price || '0'));
    }, 0).toFixed(2)}`);

    // Insert operations in batches
    console.log('\nâš¡ Starting batch insertion...');
    const totalInserted = await insertInBatches('operations', operations);

    // Final summary
    console.log('\nðŸ“Š OPERATIONS MIGRATION SUMMARY:');
    console.log(`âœ… Source operations: ${operationsResult.rows.length}`);
    console.log(`âœ… Successfully migrated: ${totalInserted}`);
    console.log(`âœ… Success rate: ${((totalInserted / operationsResult.rows.length) * 100).toFixed(1)}%`);

    const migratedValue = operations.slice(0, totalInserted).reduce((sum: number, op: any) => {
      return sum + (parseFloat(op.metadata?.price || '0'));
    }, 0);

    console.log(`ðŸ’° Total value migrated: $${migratedValue.toFixed(2)}`);

    // Show operation type distribution
    if (totalInserted > 0) {
      const migratedOps = operations.slice(0, totalInserted);
      const typeDistribution = migratedOps.reduce((acc: any, op: any) => {
        acc[op.operation_type] = (acc[op.operation_type] || 0) + 1;
        return acc;
      }, {});

      console.log('\nðŸ“ˆ Migrated operation types:');
      Object.entries(typeDistribution).forEach(([type, count]) => {
        console.log(`   ${type}: ${count} operations`);
      });
    }

    // Verify final count
    const { count: finalCount } = await supabase
      .from('operations')
      .select('*', { count: 'exact', head: true });

    console.log(`ðŸ“¦ Final operations count in database: ${finalCount || 0}`);

    if (totalInserted > 0) {
      console.log('\nðŸŽ‰ Operations migration completed successfully!');
      console.log('ðŸ’³ Square payment operations with full card details preserved in metadata JSON');
      console.log('ðŸ”— All financial data linked to default case for relationship integrity');
    } else {
      console.log('\nâš ï¸  Operations migration completed with issues - check errors above');
    }

    return totalInserted;

  } catch (error: any) {
    console.error('âŒ Operations migration failed:', error);
    throw error;
  } finally {
    await sourceClient.end();
    console.log('ðŸ”Œ Disconnected from source database');
  }
}

// Run the migration
if (require.main === module) {
  migrateOperationsWithSchema().catch(error => {
    console.error('Fatal error:', error);
    process.exit(1);
  });
}

export default migrateOperationsWithSchema;